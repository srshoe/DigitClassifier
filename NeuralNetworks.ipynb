{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sItYpkC5Pg72"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    transform = ToTensor(),\n",
        "    download = True\n",
        ")\n",
        "test_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    transform = ToTensor(),\n",
        "    download = True\n",
        ")"
      ],
      "metadata": {
        "id": "oJO-Y6K3YjWi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Example"
      ],
      "metadata": {
        "id": "Ui8D9EZomDxB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TeEQTuXRmJJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8819TFANQdiH",
        "outputId": "92f39110-4369-4969-eddc-3bc059c2b617"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVRxEUbvZOn9",
        "outputId": "b32fc22e-2cc5-4652-b4ee-77669561ab46"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YCwDjoGZT24",
        "outputId": "27c96a7b-eded-42d9-8cf4-bd70bee7768a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSbSBZ8GZa-N",
        "outputId": "417357ed-2a85-463e-d452-b173c587b09c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqIFfrxiZgS7",
        "outputId": "65f7e49c-640e-4616-cbf1-efb13860a0e9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4,  ..., 5, 6, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "loaders = {\n",
        "    'train' : DataLoader(train_data,\n",
        "                         batch_size = 100,\n",
        "                         shuffle = True,\n",
        "                         num_workers = 1),\n",
        "\n",
        "    'test' : DataLoader(test_data,\n",
        "                        batch_size = 100,\n",
        "                        shuffle = True,\n",
        "                        num_workers = 1),\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "FADzD9FFZjRB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YabSrhP7aGVN",
        "outputId": "0a5febd4-1780-4d68-98d4-5bf14a1fe7b8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x7a65c470bf40>,\n",
              " 'test': <torch.utils.data.dataloader.DataLoader at 0x7a65c4708df0>}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 10, kernel_size = 5)\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size= 5)\n",
        "    self.conv2_drop = nn.Dropout2d() #randomly deactivates nodes in network during training. Irrelevant during testing and evaluation.\n",
        "    self.fc1 = nn.Linear(320, 50)\n",
        "    self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "    x = x.view(-1, 320)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, training = self.training)\n",
        "    x = self.fc2(x)\n",
        "    return F.softmax(x)\n"
      ],
      "metadata": {
        "id": "spRiwbZlaIAN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = loss_fn(output, target)\n",
        "    loss.backward()\n",
        "\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = loss_fn(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % 20 == 0:\n",
        "      print(f'Train Epoch: {epoch} [{batch_idx * len(data)} / {len(loaders[\"train\"].dataset)} ({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\t{loss.item():.6f}')\n",
        "\n",
        "def test():\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data, target in loaders['test']:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      test_loss += loss_fn(output, target).item()\n",
        "      pred = output.argmax(dim=1, keepdim = True)\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(loaders['test'].dataset)\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accurary {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct / len(loaders[\"test\"].dataset):.0f}%\\n)')"
      ],
      "metadata": {
        "id": "iDvKtigVb3XM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 11):\n",
        "  train(epoch)\n",
        "  test()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIFDXhlDjMCN",
        "outputId": "3a5a3aa5-4d4a-4e45-e74f-cb9c54121486"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-e780c4099691>:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0 / 60000 (0%)]\t2.304431\n",
            "Train Epoch: 1 [2000 / 60000 (3%)]\t2.290511\n",
            "Train Epoch: 1 [4000 / 60000 (7%)]\t2.139374\n",
            "Train Epoch: 1 [6000 / 60000 (10%)]\t1.998302\n",
            "Train Epoch: 1 [8000 / 60000 (13%)]\t1.978837\n",
            "Train Epoch: 1 [10000 / 60000 (17%)]\t1.872200\n",
            "Train Epoch: 1 [12000 / 60000 (20%)]\t1.798493\n",
            "Train Epoch: 1 [14000 / 60000 (23%)]\t1.729657\n",
            "Train Epoch: 1 [16000 / 60000 (27%)]\t1.741107\n",
            "Train Epoch: 1 [18000 / 60000 (30%)]\t1.698750\n",
            "Train Epoch: 1 [20000 / 60000 (33%)]\t1.762203\n",
            "Train Epoch: 1 [22000 / 60000 (37%)]\t1.658671\n",
            "Train Epoch: 1 [24000 / 60000 (40%)]\t1.627796\n",
            "Train Epoch: 1 [26000 / 60000 (43%)]\t1.623584\n",
            "Train Epoch: 1 [28000 / 60000 (47%)]\t1.666889\n",
            "Train Epoch: 1 [30000 / 60000 (50%)]\t1.662208\n",
            "Train Epoch: 1 [32000 / 60000 (53%)]\t1.595821\n",
            "Train Epoch: 1 [34000 / 60000 (57%)]\t1.597839\n",
            "Train Epoch: 1 [36000 / 60000 (60%)]\t1.606019\n",
            "Train Epoch: 1 [38000 / 60000 (63%)]\t1.608866\n",
            "Train Epoch: 1 [40000 / 60000 (67%)]\t1.612641\n",
            "Train Epoch: 1 [42000 / 60000 (70%)]\t1.548871\n",
            "Train Epoch: 1 [44000 / 60000 (73%)]\t1.597070\n",
            "Train Epoch: 1 [46000 / 60000 (77%)]\t1.579910\n",
            "Train Epoch: 1 [48000 / 60000 (80%)]\t1.616615\n",
            "Train Epoch: 1 [50000 / 60000 (83%)]\t1.588691\n",
            "Train Epoch: 1 [52000 / 60000 (87%)]\t1.542031\n",
            "Train Epoch: 1 [54000 / 60000 (90%)]\t1.589080\n",
            "Train Epoch: 1 [56000 / 60000 (93%)]\t1.561734\n",
            "Train Epoch: 1 [58000 / 60000 (97%)]\t1.629327\n",
            "\n",
            "Test set: Average loss: 0.0153, Accurary 9351/10000 (94%\n",
            ")\n",
            "Train Epoch: 2 [0 / 60000 (0%)]\t1.582591\n",
            "Train Epoch: 2 [2000 / 60000 (3%)]\t1.573169\n",
            "Train Epoch: 2 [4000 / 60000 (7%)]\t1.602739\n",
            "Train Epoch: 2 [6000 / 60000 (10%)]\t1.549510\n",
            "Train Epoch: 2 [8000 / 60000 (13%)]\t1.569222\n",
            "Train Epoch: 2 [10000 / 60000 (17%)]\t1.596138\n",
            "Train Epoch: 2 [12000 / 60000 (20%)]\t1.566331\n",
            "Train Epoch: 2 [14000 / 60000 (23%)]\t1.612476\n",
            "Train Epoch: 2 [16000 / 60000 (27%)]\t1.625942\n",
            "Train Epoch: 2 [18000 / 60000 (30%)]\t1.545864\n",
            "Train Epoch: 2 [20000 / 60000 (33%)]\t1.563351\n",
            "Train Epoch: 2 [22000 / 60000 (37%)]\t1.615358\n",
            "Train Epoch: 2 [24000 / 60000 (40%)]\t1.566335\n",
            "Train Epoch: 2 [26000 / 60000 (43%)]\t1.572375\n",
            "Train Epoch: 2 [28000 / 60000 (47%)]\t1.619438\n",
            "Train Epoch: 2 [30000 / 60000 (50%)]\t1.587364\n",
            "Train Epoch: 2 [32000 / 60000 (53%)]\t1.626887\n",
            "Train Epoch: 2 [34000 / 60000 (57%)]\t1.544438\n",
            "Train Epoch: 2 [36000 / 60000 (60%)]\t1.591438\n",
            "Train Epoch: 2 [38000 / 60000 (63%)]\t1.525633\n",
            "Train Epoch: 2 [40000 / 60000 (67%)]\t1.576570\n",
            "Train Epoch: 2 [42000 / 60000 (70%)]\t1.561250\n",
            "Train Epoch: 2 [44000 / 60000 (73%)]\t1.581842\n",
            "Train Epoch: 2 [46000 / 60000 (77%)]\t1.564032\n",
            "Train Epoch: 2 [48000 / 60000 (80%)]\t1.608611\n",
            "Train Epoch: 2 [50000 / 60000 (83%)]\t1.555809\n",
            "Train Epoch: 2 [52000 / 60000 (87%)]\t1.586264\n",
            "Train Epoch: 2 [54000 / 60000 (90%)]\t1.521576\n",
            "Train Epoch: 2 [56000 / 60000 (93%)]\t1.588352\n",
            "Train Epoch: 2 [58000 / 60000 (97%)]\t1.563688\n",
            "\n",
            "Test set: Average loss: 0.0151, Accurary 9510/10000 (95%\n",
            ")\n",
            "Train Epoch: 3 [0 / 60000 (0%)]\t1.543062\n",
            "Train Epoch: 3 [2000 / 60000 (3%)]\t1.574671\n",
            "Train Epoch: 3 [4000 / 60000 (7%)]\t1.580705\n",
            "Train Epoch: 3 [6000 / 60000 (10%)]\t1.619049\n",
            "Train Epoch: 3 [8000 / 60000 (13%)]\t1.532433\n",
            "Train Epoch: 3 [10000 / 60000 (17%)]\t1.539450\n",
            "Train Epoch: 3 [12000 / 60000 (20%)]\t1.588878\n",
            "Train Epoch: 3 [14000 / 60000 (23%)]\t1.540347\n",
            "Train Epoch: 3 [16000 / 60000 (27%)]\t1.520736\n",
            "Train Epoch: 3 [18000 / 60000 (30%)]\t1.610010\n",
            "Train Epoch: 3 [20000 / 60000 (33%)]\t1.571877\n",
            "Train Epoch: 3 [22000 / 60000 (37%)]\t1.538420\n",
            "Train Epoch: 3 [24000 / 60000 (40%)]\t1.568322\n",
            "Train Epoch: 3 [26000 / 60000 (43%)]\t1.573769\n",
            "Train Epoch: 3 [28000 / 60000 (47%)]\t1.545407\n",
            "Train Epoch: 3 [30000 / 60000 (50%)]\t1.591399\n",
            "Train Epoch: 3 [32000 / 60000 (53%)]\t1.573563\n",
            "Train Epoch: 3 [34000 / 60000 (57%)]\t1.574544\n",
            "Train Epoch: 3 [36000 / 60000 (60%)]\t1.562632\n",
            "Train Epoch: 3 [38000 / 60000 (63%)]\t1.510538\n",
            "Train Epoch: 3 [40000 / 60000 (67%)]\t1.565186\n",
            "Train Epoch: 3 [42000 / 60000 (70%)]\t1.537016\n",
            "Train Epoch: 3 [44000 / 60000 (73%)]\t1.493925\n",
            "Train Epoch: 3 [46000 / 60000 (77%)]\t1.556534\n",
            "Train Epoch: 3 [48000 / 60000 (80%)]\t1.520299\n",
            "Train Epoch: 3 [50000 / 60000 (83%)]\t1.523579\n",
            "Train Epoch: 3 [52000 / 60000 (87%)]\t1.544082\n",
            "Train Epoch: 3 [54000 / 60000 (90%)]\t1.516200\n",
            "Train Epoch: 3 [56000 / 60000 (93%)]\t1.550858\n",
            "Train Epoch: 3 [58000 / 60000 (97%)]\t1.584782\n",
            "\n",
            "Test set: Average loss: 0.0150, Accurary 9621/10000 (96%\n",
            ")\n",
            "Train Epoch: 4 [0 / 60000 (0%)]\t1.527936\n",
            "Train Epoch: 4 [2000 / 60000 (3%)]\t1.546292\n",
            "Train Epoch: 4 [4000 / 60000 (7%)]\t1.547810\n",
            "Train Epoch: 4 [6000 / 60000 (10%)]\t1.635650\n",
            "Train Epoch: 4 [8000 / 60000 (13%)]\t1.554857\n",
            "Train Epoch: 4 [10000 / 60000 (17%)]\t1.531294\n",
            "Train Epoch: 4 [12000 / 60000 (20%)]\t1.476539\n",
            "Train Epoch: 4 [14000 / 60000 (23%)]\t1.571429\n",
            "Train Epoch: 4 [16000 / 60000 (27%)]\t1.528350\n",
            "Train Epoch: 4 [18000 / 60000 (30%)]\t1.531867\n",
            "Train Epoch: 4 [20000 / 60000 (33%)]\t1.524989\n",
            "Train Epoch: 4 [22000 / 60000 (37%)]\t1.575703\n",
            "Train Epoch: 4 [24000 / 60000 (40%)]\t1.530817\n",
            "Train Epoch: 4 [26000 / 60000 (43%)]\t1.556489\n",
            "Train Epoch: 4 [28000 / 60000 (47%)]\t1.571168\n",
            "Train Epoch: 4 [30000 / 60000 (50%)]\t1.559078\n",
            "Train Epoch: 4 [32000 / 60000 (53%)]\t1.546805\n",
            "Train Epoch: 4 [34000 / 60000 (57%)]\t1.514915\n",
            "Train Epoch: 4 [36000 / 60000 (60%)]\t1.533939\n",
            "Train Epoch: 4 [38000 / 60000 (63%)]\t1.537219\n",
            "Train Epoch: 4 [40000 / 60000 (67%)]\t1.513787\n",
            "Train Epoch: 4 [42000 / 60000 (70%)]\t1.547423\n",
            "Train Epoch: 4 [44000 / 60000 (73%)]\t1.557952\n",
            "Train Epoch: 4 [46000 / 60000 (77%)]\t1.560995\n",
            "Train Epoch: 4 [48000 / 60000 (80%)]\t1.541557\n",
            "Train Epoch: 4 [50000 / 60000 (83%)]\t1.530559\n",
            "Train Epoch: 4 [52000 / 60000 (87%)]\t1.509072\n",
            "Train Epoch: 4 [54000 / 60000 (90%)]\t1.507885\n",
            "Train Epoch: 4 [56000 / 60000 (93%)]\t1.541356\n",
            "Train Epoch: 4 [58000 / 60000 (97%)]\t1.531974\n",
            "\n",
            "Test set: Average loss: 0.0150, Accurary 9643/10000 (96%\n",
            ")\n",
            "Train Epoch: 5 [0 / 60000 (0%)]\t1.508941\n",
            "Train Epoch: 5 [2000 / 60000 (3%)]\t1.533815\n",
            "Train Epoch: 5 [4000 / 60000 (7%)]\t1.529438\n",
            "Train Epoch: 5 [6000 / 60000 (10%)]\t1.544234\n",
            "Train Epoch: 5 [8000 / 60000 (13%)]\t1.560885\n",
            "Train Epoch: 5 [10000 / 60000 (17%)]\t1.524175\n",
            "Train Epoch: 5 [12000 / 60000 (20%)]\t1.516406\n",
            "Train Epoch: 5 [14000 / 60000 (23%)]\t1.527833\n",
            "Train Epoch: 5 [16000 / 60000 (27%)]\t1.514318\n",
            "Train Epoch: 5 [18000 / 60000 (30%)]\t1.538449\n",
            "Train Epoch: 5 [20000 / 60000 (33%)]\t1.560990\n",
            "Train Epoch: 5 [22000 / 60000 (37%)]\t1.554398\n",
            "Train Epoch: 5 [24000 / 60000 (40%)]\t1.543277\n",
            "Train Epoch: 5 [26000 / 60000 (43%)]\t1.534566\n",
            "Train Epoch: 5 [28000 / 60000 (47%)]\t1.514920\n",
            "Train Epoch: 5 [30000 / 60000 (50%)]\t1.584923\n",
            "Train Epoch: 5 [32000 / 60000 (53%)]\t1.529862\n",
            "Train Epoch: 5 [34000 / 60000 (57%)]\t1.578894\n",
            "Train Epoch: 5 [36000 / 60000 (60%)]\t1.510377\n",
            "Train Epoch: 5 [38000 / 60000 (63%)]\t1.571643\n",
            "Train Epoch: 5 [40000 / 60000 (67%)]\t1.618674\n",
            "Train Epoch: 5 [42000 / 60000 (70%)]\t1.542400\n",
            "Train Epoch: 5 [44000 / 60000 (73%)]\t1.560367\n",
            "Train Epoch: 5 [46000 / 60000 (77%)]\t1.564792\n",
            "Train Epoch: 5 [48000 / 60000 (80%)]\t1.558190\n",
            "Train Epoch: 5 [50000 / 60000 (83%)]\t1.555948\n",
            "Train Epoch: 5 [52000 / 60000 (87%)]\t1.532194\n",
            "Train Epoch: 5 [54000 / 60000 (90%)]\t1.536676\n",
            "Train Epoch: 5 [56000 / 60000 (93%)]\t1.569450\n",
            "Train Epoch: 5 [58000 / 60000 (97%)]\t1.549592\n",
            "\n",
            "Test set: Average loss: 0.0149, Accurary 9681/10000 (97%\n",
            ")\n",
            "Train Epoch: 6 [0 / 60000 (0%)]\t1.507122\n",
            "Train Epoch: 6 [2000 / 60000 (3%)]\t1.536881\n",
            "Train Epoch: 6 [4000 / 60000 (7%)]\t1.536283\n",
            "Train Epoch: 6 [6000 / 60000 (10%)]\t1.539608\n",
            "Train Epoch: 6 [8000 / 60000 (13%)]\t1.554546\n",
            "Train Epoch: 6 [10000 / 60000 (17%)]\t1.534250\n",
            "Train Epoch: 6 [12000 / 60000 (20%)]\t1.558027\n",
            "Train Epoch: 6 [14000 / 60000 (23%)]\t1.590420\n",
            "Train Epoch: 6 [16000 / 60000 (27%)]\t1.513153\n",
            "Train Epoch: 6 [18000 / 60000 (30%)]\t1.526536\n",
            "Train Epoch: 6 [20000 / 60000 (33%)]\t1.545419\n",
            "Train Epoch: 6 [22000 / 60000 (37%)]\t1.541355\n",
            "Train Epoch: 6 [24000 / 60000 (40%)]\t1.564086\n",
            "Train Epoch: 6 [26000 / 60000 (43%)]\t1.590219\n",
            "Train Epoch: 6 [28000 / 60000 (47%)]\t1.548213\n",
            "Train Epoch: 6 [30000 / 60000 (50%)]\t1.544010\n",
            "Train Epoch: 6 [32000 / 60000 (53%)]\t1.538151\n",
            "Train Epoch: 6 [34000 / 60000 (57%)]\t1.551074\n",
            "Train Epoch: 6 [36000 / 60000 (60%)]\t1.528800\n",
            "Train Epoch: 6 [38000 / 60000 (63%)]\t1.537394\n",
            "Train Epoch: 6 [40000 / 60000 (67%)]\t1.522021\n",
            "Train Epoch: 6 [42000 / 60000 (70%)]\t1.532850\n",
            "Train Epoch: 6 [44000 / 60000 (73%)]\t1.530420\n",
            "Train Epoch: 6 [46000 / 60000 (77%)]\t1.535046\n",
            "Train Epoch: 6 [48000 / 60000 (80%)]\t1.511569\n",
            "Train Epoch: 6 [50000 / 60000 (83%)]\t1.541755\n",
            "Train Epoch: 6 [52000 / 60000 (87%)]\t1.518701\n",
            "Train Epoch: 6 [54000 / 60000 (90%)]\t1.579002\n",
            "Train Epoch: 6 [56000 / 60000 (93%)]\t1.491397\n",
            "Train Epoch: 6 [58000 / 60000 (97%)]\t1.530717\n",
            "\n",
            "Test set: Average loss: 0.0149, Accurary 9703/10000 (97%\n",
            ")\n",
            "Train Epoch: 7 [0 / 60000 (0%)]\t1.501813\n",
            "Train Epoch: 7 [2000 / 60000 (3%)]\t1.521631\n",
            "Train Epoch: 7 [4000 / 60000 (7%)]\t1.528492\n",
            "Train Epoch: 7 [6000 / 60000 (10%)]\t1.490819\n",
            "Train Epoch: 7 [8000 / 60000 (13%)]\t1.509399\n",
            "Train Epoch: 7 [10000 / 60000 (17%)]\t1.540652\n",
            "Train Epoch: 7 [12000 / 60000 (20%)]\t1.552055\n",
            "Train Epoch: 7 [14000 / 60000 (23%)]\t1.516949\n",
            "Train Epoch: 7 [16000 / 60000 (27%)]\t1.573869\n",
            "Train Epoch: 7 [18000 / 60000 (30%)]\t1.499575\n",
            "Train Epoch: 7 [20000 / 60000 (33%)]\t1.527331\n",
            "Train Epoch: 7 [22000 / 60000 (37%)]\t1.514187\n",
            "Train Epoch: 7 [24000 / 60000 (40%)]\t1.508206\n",
            "Train Epoch: 7 [26000 / 60000 (43%)]\t1.528238\n",
            "Train Epoch: 7 [28000 / 60000 (47%)]\t1.543008\n",
            "Train Epoch: 7 [30000 / 60000 (50%)]\t1.563375\n",
            "Train Epoch: 7 [32000 / 60000 (53%)]\t1.548140\n",
            "Train Epoch: 7 [34000 / 60000 (57%)]\t1.539544\n",
            "Train Epoch: 7 [36000 / 60000 (60%)]\t1.513411\n",
            "Train Epoch: 7 [38000 / 60000 (63%)]\t1.519566\n",
            "Train Epoch: 7 [40000 / 60000 (67%)]\t1.510605\n",
            "Train Epoch: 7 [42000 / 60000 (70%)]\t1.554119\n",
            "Train Epoch: 7 [44000 / 60000 (73%)]\t1.556659\n",
            "Train Epoch: 7 [46000 / 60000 (77%)]\t1.503896\n",
            "Train Epoch: 7 [48000 / 60000 (80%)]\t1.572274\n",
            "Train Epoch: 7 [50000 / 60000 (83%)]\t1.473607\n",
            "Train Epoch: 7 [52000 / 60000 (87%)]\t1.547235\n",
            "Train Epoch: 7 [54000 / 60000 (90%)]\t1.523807\n",
            "Train Epoch: 7 [56000 / 60000 (93%)]\t1.554672\n",
            "Train Epoch: 7 [58000 / 60000 (97%)]\t1.548495\n",
            "\n",
            "Test set: Average loss: 0.0149, Accurary 9718/10000 (97%\n",
            ")\n",
            "Train Epoch: 8 [0 / 60000 (0%)]\t1.486257\n",
            "Train Epoch: 8 [2000 / 60000 (3%)]\t1.524062\n",
            "Train Epoch: 8 [4000 / 60000 (7%)]\t1.520350\n",
            "Train Epoch: 8 [6000 / 60000 (10%)]\t1.538550\n",
            "Train Epoch: 8 [8000 / 60000 (13%)]\t1.512672\n",
            "Train Epoch: 8 [10000 / 60000 (17%)]\t1.542249\n",
            "Train Epoch: 8 [12000 / 60000 (20%)]\t1.530426\n",
            "Train Epoch: 8 [14000 / 60000 (23%)]\t1.547197\n",
            "Train Epoch: 8 [16000 / 60000 (27%)]\t1.523752\n",
            "Train Epoch: 8 [18000 / 60000 (30%)]\t1.500641\n",
            "Train Epoch: 8 [20000 / 60000 (33%)]\t1.537467\n",
            "Train Epoch: 8 [22000 / 60000 (37%)]\t1.530904\n",
            "Train Epoch: 8 [24000 / 60000 (40%)]\t1.500010\n",
            "Train Epoch: 8 [26000 / 60000 (43%)]\t1.525971\n",
            "Train Epoch: 8 [28000 / 60000 (47%)]\t1.524530\n",
            "Train Epoch: 8 [30000 / 60000 (50%)]\t1.544726\n",
            "Train Epoch: 8 [32000 / 60000 (53%)]\t1.509874\n",
            "Train Epoch: 8 [34000 / 60000 (57%)]\t1.520634\n",
            "Train Epoch: 8 [36000 / 60000 (60%)]\t1.552289\n",
            "Train Epoch: 8 [38000 / 60000 (63%)]\t1.526191\n",
            "Train Epoch: 8 [40000 / 60000 (67%)]\t1.557413\n",
            "Train Epoch: 8 [42000 / 60000 (70%)]\t1.552623\n",
            "Train Epoch: 8 [44000 / 60000 (73%)]\t1.492948\n",
            "Train Epoch: 8 [46000 / 60000 (77%)]\t1.518649\n",
            "Train Epoch: 8 [48000 / 60000 (80%)]\t1.514590\n",
            "Train Epoch: 8 [50000 / 60000 (83%)]\t1.510054\n",
            "Train Epoch: 8 [52000 / 60000 (87%)]\t1.509562\n",
            "Train Epoch: 8 [54000 / 60000 (90%)]\t1.518193\n",
            "Train Epoch: 8 [56000 / 60000 (93%)]\t1.540476\n",
            "Train Epoch: 8 [58000 / 60000 (97%)]\t1.531611\n",
            "\n",
            "Test set: Average loss: 0.0149, Accurary 9738/10000 (97%\n",
            ")\n",
            "Train Epoch: 9 [0 / 60000 (0%)]\t1.509827\n",
            "Train Epoch: 9 [2000 / 60000 (3%)]\t1.502741\n",
            "Train Epoch: 9 [4000 / 60000 (7%)]\t1.557719\n",
            "Train Epoch: 9 [6000 / 60000 (10%)]\t1.498284\n",
            "Train Epoch: 9 [8000 / 60000 (13%)]\t1.513535\n",
            "Train Epoch: 9 [10000 / 60000 (17%)]\t1.540858\n",
            "Train Epoch: 9 [12000 / 60000 (20%)]\t1.550364\n",
            "Train Epoch: 9 [14000 / 60000 (23%)]\t1.527918\n",
            "Train Epoch: 9 [16000 / 60000 (27%)]\t1.592539\n",
            "Train Epoch: 9 [18000 / 60000 (30%)]\t1.517409\n",
            "Train Epoch: 9 [20000 / 60000 (33%)]\t1.539644\n",
            "Train Epoch: 9 [22000 / 60000 (37%)]\t1.531924\n",
            "Train Epoch: 9 [24000 / 60000 (40%)]\t1.522660\n",
            "Train Epoch: 9 [26000 / 60000 (43%)]\t1.511924\n",
            "Train Epoch: 9 [28000 / 60000 (47%)]\t1.516080\n",
            "Train Epoch: 9 [30000 / 60000 (50%)]\t1.512554\n",
            "Train Epoch: 9 [32000 / 60000 (53%)]\t1.513151\n",
            "Train Epoch: 9 [34000 / 60000 (57%)]\t1.510552\n",
            "Train Epoch: 9 [36000 / 60000 (60%)]\t1.490335\n",
            "Train Epoch: 9 [38000 / 60000 (63%)]\t1.547690\n",
            "Train Epoch: 9 [40000 / 60000 (67%)]\t1.571606\n",
            "Train Epoch: 9 [42000 / 60000 (70%)]\t1.511518\n",
            "Train Epoch: 9 [44000 / 60000 (73%)]\t1.535014\n",
            "Train Epoch: 9 [46000 / 60000 (77%)]\t1.486773\n",
            "Train Epoch: 9 [48000 / 60000 (80%)]\t1.508966\n",
            "Train Epoch: 9 [50000 / 60000 (83%)]\t1.528870\n",
            "Train Epoch: 9 [52000 / 60000 (87%)]\t1.514821\n",
            "Train Epoch: 9 [54000 / 60000 (90%)]\t1.515522\n",
            "Train Epoch: 9 [56000 / 60000 (93%)]\t1.545510\n",
            "Train Epoch: 9 [58000 / 60000 (97%)]\t1.533372\n",
            "\n",
            "Test set: Average loss: 0.0149, Accurary 9755/10000 (98%\n",
            ")\n",
            "Train Epoch: 10 [0 / 60000 (0%)]\t1.528122\n",
            "Train Epoch: 10 [2000 / 60000 (3%)]\t1.547229\n",
            "Train Epoch: 10 [4000 / 60000 (7%)]\t1.528593\n",
            "Train Epoch: 10 [6000 / 60000 (10%)]\t1.548834\n",
            "Train Epoch: 10 [8000 / 60000 (13%)]\t1.492123\n",
            "Train Epoch: 10 [10000 / 60000 (17%)]\t1.537969\n",
            "Train Epoch: 10 [12000 / 60000 (20%)]\t1.505790\n",
            "Train Epoch: 10 [14000 / 60000 (23%)]\t1.542905\n",
            "Train Epoch: 10 [16000 / 60000 (27%)]\t1.525488\n",
            "Train Epoch: 10 [18000 / 60000 (30%)]\t1.505558\n",
            "Train Epoch: 10 [20000 / 60000 (33%)]\t1.484238\n",
            "Train Epoch: 10 [22000 / 60000 (37%)]\t1.515193\n",
            "Train Epoch: 10 [24000 / 60000 (40%)]\t1.525317\n",
            "Train Epoch: 10 [26000 / 60000 (43%)]\t1.532963\n",
            "Train Epoch: 10 [28000 / 60000 (47%)]\t1.500188\n",
            "Train Epoch: 10 [30000 / 60000 (50%)]\t1.516402\n",
            "Train Epoch: 10 [32000 / 60000 (53%)]\t1.518966\n",
            "Train Epoch: 10 [34000 / 60000 (57%)]\t1.578862\n",
            "Train Epoch: 10 [36000 / 60000 (60%)]\t1.500480\n",
            "Train Epoch: 10 [38000 / 60000 (63%)]\t1.526697\n",
            "Train Epoch: 10 [40000 / 60000 (67%)]\t1.473186\n",
            "Train Epoch: 10 [42000 / 60000 (70%)]\t1.530725\n",
            "Train Epoch: 10 [44000 / 60000 (73%)]\t1.526672\n",
            "Train Epoch: 10 [46000 / 60000 (77%)]\t1.520441\n",
            "Train Epoch: 10 [48000 / 60000 (80%)]\t1.531221\n",
            "Train Epoch: 10 [50000 / 60000 (83%)]\t1.512240\n",
            "Train Epoch: 10 [52000 / 60000 (87%)]\t1.527084\n",
            "Train Epoch: 10 [54000 / 60000 (90%)]\t1.481464\n",
            "Train Epoch: 10 [56000 / 60000 (93%)]\t1.504981\n",
            "Train Epoch: 10 [58000 / 60000 (97%)]\t1.507906\n",
            "\n",
            "Test set: Average loss: 0.0148, Accurary 9765/10000 (98%\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIk-jKoBj8Ac",
        "outputId": "2d03df24-2fe3-4d37-f593-b6f2cda713ca"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "model.eval()\n",
        "data, target = test_data[10]\n",
        "\n",
        "data = data.unsqueeze(0).to(device)\n",
        "output = model(data)\n",
        "prediction = output.argmax(dim=1, keepdim=True).item()\n",
        "print(f'Prediction: {prediction}')\n",
        "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
        "\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "t8LKkFFGkAaG",
        "outputId": "41eb622e-8cea-4788-ce8e-5c3ce0f575b7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-e780c4099691>:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}